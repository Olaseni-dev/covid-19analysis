name: 'Process Data'

on:
  push:
    branches: [ main ]
  schedule:
    # Upstream repo is updated daily at 4:50 AM UTC:
    # we can retrieve data a little while later.
    - cron: '0 6 * * *'

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3  # Update to the latest version
    - name: Set up Python 3.8
      uses: actions/setup-python@v4  # Use the latest version to support Node.js 20
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f scripts/requirements.txt ]; then pip install -r scripts/requirements.txt; fi
    - name: Process Data
      run: |
        python scripts/process_worldwide.py
        python scripts/process_us.py
    - name: Commit files
      uses: github-actions-x/commit@v3  # Alternative to ad-m/github-push-action
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        commit_message: "Auto-update of the data packages"

  deploy:
    needs: update
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3  # Update to the latest version
    - uses: actions/setup-node@v4  # Use the latest version to support Node.js 20
      with:
        node-version: '18.x'  # Use a more recent LTS version
    - name: Install data-cli and init package
      run: |
        npm install -g data-cli
        data --version
        data init data
    - name: Update metadata and publish to DataHub
      run: |
        python scripts/update_datapackage.py
        data push
      env:
        id: ${{ secrets.dhid }}
        username: ${{ secrets.dhusername }}
        token: ${{ secrets.dhtoken }}
