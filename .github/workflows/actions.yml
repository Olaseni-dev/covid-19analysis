name: 'Process Data'

on:
  push:
    branches: [ main ]
  schedule:
    # Upstream repo is updated daily at 4:50 AM UTC:
    # we can retrieve data a little while later.
    - cron: '0 6 * * *'

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python 3.8
      uses: actions/setup-python@v4
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f scripts/requirements.txt ]; then pip install -r scripts/requirements.txt; fi
    - name: Process Data
      run: |
        python scripts/process_worldwide.py
        python scripts/process_us.py
    - name: Commit files
      uses: stefanzweifel/git-auto-commit-action@v4
      with:
        commit_message: "Auto-update of the data packages"
        commit_user_name: GitHub Action
        commit_user_email: action@github.com
        branch: main

  deploy:
    needs: update
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - uses: actions/setup-node@v4
      with:
        node-version: '20.x'  # Explicitly specify Node.js 20
    - name: Install data-cli and init package
      run: |
        npm install -g data-cli
        data --version
        data init data
    - name: Update metadata and publish to DataHub
      run: |
        python scripts/update_datapackage.py
        data push
      env:
        id: ${{ secrets.dhid }}
        username: ${{ secrets.dhusername }}
        token: ${{ secrets.dhtoken }}
